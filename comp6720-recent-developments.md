# Recent developments

My artwork incorporates cutting-edge developments in computer vision and AR interaction through the ml5.js library, specifically utilizing handPose and faceMesh models for natural user interaction. These technologies represent recent advances in making machine learning accessible for creative coding and interactive art.

The project implements two key modern interaction paradigms:

1. Computer Vision-based Gesture Control:
   - Hand tracking for intuitive object manipulation
   - Finger pinch detection for precise interaction
   - Face landmark detection for expression-based control
   - Real-time pose estimation for natural movement recognition
2. Multi-modal Interaction Design:
   - Seamless integration of traditional inputs (mouse/keyboard) with AR controls
   - Natural mapping of physical gestures to digital effects (mouth opening to rain intensity)
   - Real-time visual feedback through the black cursor
   - Adaptive interface supporting both precise and gesture-based interactions

These implementations reflect current trends in human-computer interaction, where the focus is shifting towards more natural and intuitive interfaces. The project demonstrates how modern AR technologies can create engaging interactive experiences without requiring specialized hardware, making digital art more accessible while maintaining sophisticated interaction capabilities.

The artwork also explores contemporary themes in interactive art by blending environmental control with natural gestures, reflecting recent developments in creating more immersive and responsive digital experiences.